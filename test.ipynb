{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_og = pd.read_csv('trainLivraria.csv')\n",
    "\n",
    "LABELS = {'Historia': 0, 'Administracao': 1, 'Geografia': 2, 'Biologia': 3, \n",
    "          'Literatura': 4, 'Artes': 5, 'Matematica': 6}\n",
    "\n",
    "x_train_og['label'] = x_train_og['Genero'].map(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('testLivraria.csv')\n",
    "x_test['label'] = x_test['Genero'].map(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchdata.datapipes.iter import IterableWrapper, ShardingFilter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64).to(device)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0).to(device)\n",
    "    text_list = torch.cat(text_list).to(device)\n",
    "    return label_list, text_list, offsets\n",
    "\n",
    "train_iter = iter([*x_train_og[['label', 'Titulo']].itertuples(index=False, name=None)])\n",
    "# train_iter = IterableWrapper(train_iter)\n",
    "train_iter = ShardingFilter(train_iter)\n",
    "\n",
    "test_iter = iter([*x_test[['label', 'Titulo']].itertuples(index=False, name=None)])\n",
    "test_iter = ShardingFilter(test_iter)\n",
    "                            \n",
    "train_loader = DataLoader(train_iter, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_iter, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 66]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer(\"spacy\", language='pt_core_news_sm')\n",
    "train_iter = iter([*x_train_og[['label', 'Titulo']].itertuples(index=False, name=None)])\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, rows in data_iter:\n",
    "        yield tokenizer(rows)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"[UNK]\"])\n",
    "vocab.set_default_index(vocab[\"[UNK]\"])\n",
    "\n",
    "text_pipeline = lambda word: vocab(tokenizer(word))\n",
    "label_pipeline = lambda idx: int(idx)\n",
    "\n",
    "text_pipeline('Ola, tudo bem?')\n",
    "# label_pipeline('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from torch import nn\n",
    "\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações Gerais\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do Modelo LSTM\n",
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim)        \n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "        #  dimensão do text: [sentence length, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        #  dimensão embedded: [sentence length, batch size, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        #  dimensão output: [sentence length, batch size, hidden dim]\n",
    "        #  dimensão hidden: [1, batch size, hidden dim]\n",
    "\n",
    "        hidden.squeeze_(0)\n",
    "        #  dimensão hidden: [batch size, hidden dim]\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emsize = 100\n",
    "model = RNN(vocab_size, emsize, HIDDEN_DIM ,NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "            \n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do conjunto\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "treinamento = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for text, labels in enumerate(train_loader):\n",
    "        print(text)\n",
    "        print(labels)\n",
    "        # FORWARD AND BACK PROP\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Atualizar os parâmetros do modelo\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Imprimindo Época / Tamanho do Batch / Loss\n",
    "        print (f'Época: {epoch+1}/{NUM_EPOCHS} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        resultado = compute_accuracy(model, train_loader, DEVICE)\n",
    "        print(f'Acurácia Treinamento: 'f'{resultado:.2f}%')\n",
    "        treinamento.append(resultado.item())\n",
    "        \n",
    "    print(f'Tempo decorrido: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Tempo total decorrido: {(time.time() - start_time)/60:.2f} min')\n",
    "\n",
    "# Depois de treinar o modelo com as repectivas épocas, mostrar a acurácia no conjunto de teste\n",
    "print(f'Acurácia de Teste: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "    \n",
    "predict('biologia', text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
